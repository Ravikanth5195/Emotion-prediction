{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtWPboA+8vwpjmluNt4K8w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ravikanth5195/Emotion-prediction/blob/main/Emotion_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ],
      "metadata": {
        "id": "LrbUdsXFgWDp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust the path according to where you've saved the dataset\n",
        "df = pd.read_csv('/content/Emotion_classify_Data.csv')\n",
        "\n",
        "# Check the first few rows of the dataset\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9N-5SUuigaO_",
        "outputId": "3a2fa573-496b-4d49-8cc5-2f35ff93f890"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             Comment Emotion\n",
            "0  i seriously hate one subject to death but now ...    fear\n",
            "1                 im so full of life i feel appalled   anger\n",
            "2  i sit here to write i start to dig out my feel...    fear\n",
            "3  ive been really angry with r and i feel like a...     joy\n",
            "4  i feel suspicious if there is no one outside l...    fear\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(f'[{re.escape(string.punctuation)}]', '', text)  # Remove punctuation\n",
        "    tokens = nltk.word_tokenize(text)  # Tokenize\n",
        "    tokens = [word for word in tokens if word not in stop_words]  # Remove stop words\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['clean_text'] = df['Comment'].apply(clean_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNLjysHKgoBx",
        "outputId": "3c10dbcf-4e95-43e5-a2da-0aa66b85f1c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X = vectorizer.fit_transform(df['clean_text']).toarray()\n",
        "y = df['Emotion']\n"
      ],
      "metadata": {
        "id": "PIXeL1AUgrNy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes Model"
      ],
      "metadata": {
        "id": "Ds6hdRzshjD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "2caiXllNhDWW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "xCGoC9U0hFvt",
        "outputId": "cccf57c6-d93d-4dcb-c41b-29368fab3a61"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UF2wbBOhRn8",
        "outputId": "7b94c3f2-dcd8-4374-fa00-85ac8b60ee79"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9107744107744108\n",
            "Confusion Matrix:\n",
            " [[371  12   9]\n",
            " [ 22 383  11]\n",
            " [ 28  24 328]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.88      0.95      0.91       392\n",
            "        fear       0.91      0.92      0.92       416\n",
            "         joy       0.94      0.86      0.90       380\n",
            "\n",
            "    accuracy                           0.91      1188\n",
            "   macro avg       0.91      0.91      0.91      1188\n",
            "weighted avg       0.91      0.91      0.91      1188\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Model"
      ],
      "metadata": {
        "id": "glZupjP4h-d6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(df['clean_text'])\n",
        "X_nn = tokenizer.texts_to_sequences(df['clean_text'])\n",
        "X_nn = pad_sequences(X_nn, maxlen=100)\n",
        "\n",
        "X_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(X_nn, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Encode labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train_nn = le.fit_transform(y_train_nn)\n",
        "y_test_nn = le.transform(y_test_nn)\n",
        "\n",
        "# Define Neural Network\n",
        "nn_model = Sequential()\n",
        "nn_model.add(Dense(128, input_shape=(100,), activation='relu'))\n",
        "nn_model.add(Dropout(0.5))\n",
        "nn_model.add(Dense(64, activation='relu'))\n",
        "nn_model.add(Dropout(0.5))\n",
        "nn_model.add(Dense(len(le.classes_), activation='softmax'))\n",
        "\n",
        "nn_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "nn_model.fit(X_train_nn, y_train_nn, epochs=10, batch_size=32, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLOVJdfhhV00",
        "outputId": "1d864a3a-30b7-4778-f990-3f0c5f9acdbd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.3369 - loss: 170.3607 - val_accuracy: 0.3516 - val_loss: 6.3041\n",
            "Epoch 2/10\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3439 - loss: 35.5948 - val_accuracy: 0.3411 - val_loss: 1.3207\n",
            "Epoch 3/10\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3274 - loss: 9.5002 - val_accuracy: 0.3474 - val_loss: 1.1126\n",
            "Epoch 4/10\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3330 - loss: 3.9064 - val_accuracy: 0.3453 - val_loss: 1.1052\n",
            "Epoch 5/10\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3326 - loss: 2.8235 - val_accuracy: 0.3411 - val_loss: 1.1005\n",
            "Epoch 6/10\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3275 - loss: 1.8894 - val_accuracy: 0.3158 - val_loss: 1.0988\n",
            "Epoch 7/10\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3501 - loss: 1.9722 - val_accuracy: 0.3032 - val_loss: 1.0999\n",
            "Epoch 8/10\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3414 - loss: 1.4014 - val_accuracy: 0.3053 - val_loss: 1.0996\n",
            "Epoch 9/10\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3299 - loss: 1.5729 - val_accuracy: 0.3011 - val_loss: 1.0997\n",
            "Epoch 10/10\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3513 - loss: 1.3168 - val_accuracy: 0.3032 - val_loss: 1.0993\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7aad686a2020>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn_loss, nn_accuracy = nn_model.evaluate(X_test_nn, y_test_nn)\n",
        "print(\"NN Accuracy:\", nn_accuracy)\n",
        "\n",
        "y_pred_nn = np.argmax(nn_model.predict(X_test_nn), axis=-1)\n",
        "y_pred_nn_labels = le.inverse_transform(y_pred_nn)\n",
        "\n",
        "print(\"NN Classification Report:\\n\", classification_report(y_test, y_pred_nn_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zmy2RrxMiHdK",
        "outputId": "8fe09607-8c1c-41e2-909e-d03c5d35a2cb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3128 - loss: 1.1002\n",
            "NN Accuracy: 0.32828283309936523\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "NN Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.33      0.98      0.49       392\n",
            "        fear       0.00      0.00      0.00       416\n",
            "         joy       0.24      0.02      0.03       380\n",
            "\n",
            "    accuracy                           0.33      1188\n",
            "   macro avg       0.19      0.33      0.18      1188\n",
            "weighted avg       0.19      0.33      0.17      1188\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest Classifier"
      ],
      "metadata": {
        "id": "bn4h2zx1i9J5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NB28d5sDjBrW",
        "outputId": "6e08fe72-3c13-4412-8b31-d93a1beb0fa1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.9427609427609428\n",
            "Confusion Matrix:\n",
            " [[363  16  13]\n",
            " [ 20 390   6]\n",
            " [  6   7 367]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.93      0.93      0.93       392\n",
            "        fear       0.94      0.94      0.94       416\n",
            "         joy       0.95      0.97      0.96       380\n",
            "\n",
            "    accuracy                           0.94      1188\n",
            "   macro avg       0.94      0.94      0.94      1188\n",
            "weighted avg       0.94      0.94      0.94      1188\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample new text data\n",
        "new_text = \"I am feeling very anxious about the upcoming exams.\"\n",
        "\n",
        "# Preprocess the new text (same as during training)\n",
        "cleaned_text = clean_text(new_text)\n",
        "\n",
        "# Transform the cleaned text using the same TF-IDF vectorizer used during training\n",
        "new_vector = vectorizer.transform([cleaned_text]).toarray()\n",
        "\n",
        "# Predict the emotion using the trained Random Forest model\n",
        "predicted_emotion_rf = rf_model.predict(new_vector)\n",
        "\n",
        "# Print the predicted emotion\n",
        "print(f\"Predicted Emotion (Random Forest): {predicted_emotion_rf[0]}\")\n",
        "\n",
        "# For Naive Bayes:\n",
        "predicted_emotion = model.predict(new_vector)\n",
        "print(f\"Predicted Emotion (NB): {predicted_emotion[0]}\")\n",
        "\n",
        "# For Neural Network:\n",
        "new_sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
        "new_padded_sequence = pad_sequences(new_sequence, maxlen=100)\n",
        "predicted_emotion_nn = np.argmax(nn_model.predict(new_padded_sequence), axis=-1)\n",
        "print(f\"Predicted Emotion (NN): {le.inverse_transform(predicted_emotion_nn)[0]}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWHkGaojk-lK",
        "outputId": "c2477fd1-2439-4be9-d718-e9fb7dd4554c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Emotion (Random Forest): fear\n",
            "Predicted Emotion (NB): fear\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Predicted Emotion (NN): anger\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, The predicted emotion for the given text \"I am feeling very anxious about the upcoming exams.\" is fear for both **Naive bayes (NN)** and **Random Forest** algorithms, but the **neural networks (NN)** method did not give best accuracy."
      ],
      "metadata": {
        "id": "YjEkLzvRl91c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FtadNms6mfgk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}